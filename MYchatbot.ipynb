{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c81168-3302-43dc-a0af-4ef3b9955c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6de758c-927c-4a42-b1fa-e871c4850e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import random\n",
    "import os\n",
    "import csv\n",
    "import datetime\n",
    "import nltk\n",
    "import json\n",
    "import numpy as np\n",
    "import streamlit as st\n",
    "import pyttsx3\n",
    "import speech_recognition as sr\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6641d732-5d9a-450b-90bf-d6472515af5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download required NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Load intents from the JSON file\n",
    "with open('intents.json') as file:\n",
    "    intents = json.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dd9178-650a-4fca-abd3-3ac459414268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize training data variables\n",
    "training_sentences = []\n",
    "training_labels = []\n",
    "class_labels = []\n",
    "\n",
    "# Process the intents and prepare training data\n",
    "for intent in intents['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        training_sentences.append(pattern)\n",
    "        training_labels.append(intent['tag'])  \n",
    "    if intent['tag'] not in class_labels:  \n",
    "        class_labels.append(intent['tag'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4993585d-a459-4be2-bd41-b7ae05e2555f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatize and tokenize the sentences\n",
    "def preprocess_data(sentence):\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    words = [lemmatizer.lemmatize(word.lower()) for word in words]\n",
    "    return words\n",
    "\n",
    "training_sentences = [preprocess_data(sentence) for sentence in training_sentences]\n",
    "\n",
    "# Encode labels using LabelEncoder\n",
    "le = LabelEncoder()\n",
    "training_labels = le.fit_transform(training_labels)\n",
    "\n",
    "# Convert sentences to vectors using TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "training_sentences_vectorized = vectorizer.fit_transform([' '.join(sentence) for sentence in training_sentences]).toarray()\n",
    "\n",
    "# Define the neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=training_sentences_vectorized.shape[1], activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(len(class_labels), activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(training_sentences_vectorized, np.array(training_labels), epochs=15, batch_size=8)\n",
    "\n",
    "# Evaluate the model's accuracy\n",
    "loss, accuracy = model.evaluate(training_sentences_vectorized, np.array(training_labels))\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3690cbd-cfe7-469b-ac7d-f6b368bc4875",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_intent(user_input):\n",
    "    user_input = preprocess_data(user_input)\n",
    "    user_input_vectorized = vectorizer.transform([' '.join(user_input)]).toarray()\n",
    "    prediction = model.predict(user_input_vectorized)\n",
    "    predicted_label = le.inverse_transform([np.argmax(prediction)])\n",
    "    return predicted_label[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7c3f6a-4989-4f61-9e85-6c8c04e17c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(intent):\n",
    "    for i in intents['intents']:\n",
    "        if i['tag'] == intent:  \n",
    "            return np.random.choice(i['responses'])\n",
    "    return \"Sorry, I didn't understand that.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838adf12-ddc4-4931-8add-8eb0c5683dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_messages():\n",
    "    for msg in st.session_state.messages:  # Display messages in the order they were added\n",
    "        if msg[\"role\"] == \"user\":\n",
    "            st.markdown(f\"<div style='text-align: left; color: black; background-color: lavender; padding: 10px; border-radius: 10px; margin-bottom: 10px;'>üòä : {msg['text']}</div>\", unsafe_allow_html=True)\n",
    "        else:\n",
    "            st.markdown(f\"<div style='text-align: left; color: white; background-color: MediumPurple; padding: 10px; border-radius: 10px; margin-bottom: 10px;'>ü§ñ : {msg['text']}</div>\", unsafe_allow_html=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bae194-bd56-4c6b-8d49-004b50d3ba41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def message():\n",
    "    # Check if there's at least one message in the session state\n",
    "    if len(st.session_state.messages) > 1:\n",
    "        user_message = st.session_state.messages[-2]  # Second last message is the user message\n",
    "        bot_message = st.session_state.messages[-1]   # Last message is the bot response\n",
    "\n",
    "        if user_message[\"role\"] == \"user\":\n",
    "            st.markdown(f\"\"\"\n",
    "                <div style='text-align: left; color: black; background-color: lavender; padding: 10px;border-radius: 10px; margin-bottom: 10px;'>üòä : {user_message['text']}</div>\"\"\", unsafe_allow_html=True)\n",
    "\n",
    "        if bot_message[\"role\"] == \"bot\":\n",
    "            st.markdown(f\"\"\"<div style='text-align: left; color: white; background-color: MediumPurple; padding: 10px; border-radius: 10px; margin-bottom: 10px;'>ü§ñ : {bot_message['text']}</div>\"\"\", unsafe_allow_html=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359725de-4c97-4c53-aefa-62731101c4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speak(text):\n",
    "    engine = pyttsx3.init()\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f1e4c7-22b3-4e2f-9128-adf956af59ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_speech():\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        st.info(\"Ask me something! I‚Äôm listening...\")\n",
    "        try:\n",
    "            audio = recognizer.listen(source, timeout=5, phrase_time_limit=10)\n",
    "            st.success(\"Processing your speech...\")\n",
    "            text = recognizer.recognize_google(audio)\n",
    "            st.success(f\"Recognized Speech: {text}\")\n",
    "            return text\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"Sorry, I couldn't understand the audio.\")\n",
    "            return None\n",
    "        except sr.RequestError:\n",
    "            print(\"Sorry, the speech recognition service is unavailable.\")\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30720274-bd81-42e2-96f6-dd80c6fde8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_time_chat():\n",
    "    conversation_history = []  \n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "\n",
    "        if user_input.lower() in ['exit', 'quit', 'bye']:\n",
    "            print(\"Bot: Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        predicted_intent = predict_intent(user_input)\n",
    "        bot_response = get_response(predicted_intent)\n",
    "    \n",
    "        conversation_history.append(f\"You: {user_input}\")\n",
    "        conversation_history.append(f\"Bot: {bot_response}\")\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        for message in conversation_history:\n",
    "            print(message)\n",
    "            \n",
    "real_time_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3b27a2-abe7-48d0-80e5-094836df32b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    st.title(\"Intentoü§ñ\")\n",
    "\n",
    "    # Initialize conversation state\n",
    "    if \"messages\" not in st.session_state:\n",
    "        st.session_state.messages = []\n",
    "\n",
    "    # Sidebar Menu\n",
    "    menu = [\"Home üè†\", \"Conversation History üìú\", \"About ‚ÑπÔ∏è\"]\n",
    "    choice = st.sidebar.selectbox(\"Menu\", menu)\n",
    "\n",
    "    # Home Menu\n",
    "    if choice == \"Home üè†\":\n",
    "        st.write(\"Welcome to the Chatbot! Start by typing a message üòä\")\n",
    "\n",
    "        # User input area with fixed height\n",
    "        user_input = st.text_input(\"You:\", key=\"user_input\")\n",
    "\n",
    "        # Button for predefined responses\n",
    "        col1, col2, col3 ,col4 = st.columns(4)\n",
    "        with col1:\n",
    "            if st.button(\"Speak to Me üé§\"):\n",
    "                user_input = recognize_speech()\n",
    "                if user_input:\n",
    "                    st.session_state.messages.append({\"role\": \"user\", \"text\": user_input})\n",
    "            \n",
    "                    intent = predict_intent(user_input)\n",
    "                    response = get_response(intent)\n",
    "            \n",
    "                    st.session_state.messages.append({\"role\": \"bot\", \"text\": response})\n",
    "                    speak(response)  # Speak the bot response\n",
    "\n",
    "        with col2:\n",
    "            if st.button(\"hi üëã\"):\n",
    "                user_input = \"Hello\"\n",
    "        with col3:\n",
    "            if st.button(\"Ask About the Bot ü§ñ\"):\n",
    "                user_input = \"What is your purpose?\"\n",
    "        with col4:\n",
    "            if st.button(\"Goodbye üëã\"):\n",
    "                user_input = \"Goodbye\"\n",
    "\n",
    "        if user_input:\n",
    "            # Store user message in session state\n",
    "            st.session_state.messages.append({\"role\": \"user\", \"text\": user_input})\n",
    "\n",
    "            # Get the intent and response from the chatbot\n",
    "            intent = predict_intent(user_input)\n",
    "            response = get_response(intent)\n",
    "\n",
    "            # Store chatbot response in session state\n",
    "            st.session_state.messages.append({\"role\": \"bot\", \"text\": response})\n",
    "\n",
    "        \n",
    "            messages()\n",
    "\n",
    "\n",
    "    # Conversation History Menu\n",
    "    elif choice == \"Conversation History üìú\":\n",
    "        st.header(\"Conversation History\")\n",
    "        # Display conversation history\n",
    "        display_messages()\n",
    "\n",
    "    elif choice == \"About ‚ÑπÔ∏è\":\n",
    "        st.subheader(\"About the Project\")\n",
    "        st.write(\"\"\"\n",
    "        **Intento: Intent-Based Chatbot** is a conversational chatbot that leverages Natural Language Processing (NLP) techniques and a neural network model to understand and respond to user inputs based on predefined intents.\n",
    "        The chatbot offers an interactive, user-friendly interface built with Streamlit and supports both text-based and voice-based interactions.\n",
    "        \"\"\")\n",
    "        st.subheader(\"Key Features\")\n",
    "        st.write(\"\"\"\n",
    "        1. **Intent Recognition**:\n",
    "        - Uses labeled intents and patterns stored in a JSON file to train the model.\n",
    "        - Implements TF-IDF Vectorization to convert user inputs into feature vectors.\n",
    "        - Applies a neural network model with layers for intent classification.\n",
    "        \n",
    "        2. **Interactive UI**:\n",
    "        - Built using Streamlit, offering an intuitive web interface.\n",
    "        - Includes buttons for predefined responses and voice input recognition using SpeechRecognition.\n",
    "        \n",
    "        3. **Speech Interaction:**\n",
    "        - Incorporates voice recognition with Google Speech API.\n",
    "        -Responses are vocalized using the pyttsx3 library for a more interactive experience.\n",
    "        \n",
    "        4. **Customizable Responses:**\n",
    "        - Dynamically selects appropriate responses from predefined options for each intent.\n",
    "        \n",
    "        5. **Conversation History:**\n",
    "        - Stores and displays the entire conversation for review and context.\n",
    "\n",
    "        \"\"\")\n",
    "        st.subheader(\"Dataset:\")\n",
    "        st.write(\"\"\"\n",
    "        The dataset contains labeled intents and patterns:\n",
    "        - **Intents:** Represent the goal of user inputs (e.g., \"greeting\", \"help\").\n",
    "        - **Patterns:** Text inputs corresponding to each intent.\n",
    "        - **Responses:** Possible chatbot replies for each intent.\n",
    "        \"\"\")\n",
    "        st.subheader(\"Conclusion:\")\n",
    "        st.write(\"\"\"\n",
    "        This chatbot demonstrates the application of NLP techniques and Streamlit for a functional, user-friendly chatbot. Future work may include deep learning models and expanded datasets.\n",
    "        \"\"\")\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdeec9c7-8fce-4909-b1e7-0550bf6ed0fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a63fc2-ccd5-4427-bdec-117487631e3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
